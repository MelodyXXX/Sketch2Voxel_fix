{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function, absolute_import\n",
    "import gc\n",
    "import sys\n",
    "from torch.autograd import Variable\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.optim.lr_scheduler\n",
    "torch.backends.cudnn.benchmark=True\n",
    "\n",
    "import time\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.models as models\n",
    "import numpy as np\n",
    "import random\n",
    "import cv2\n",
    "from PIL import Image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA enable:  True\n"
     ]
    }
   ],
   "source": [
    "# test CUDA available\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "print('CUDA enable: ', torch.cuda.is_available())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# import dataset from ./lib/dataset.py\n",
    "import lib.dataset as dataset\n",
    "from models.__init__ import load_model\n",
    "from lib.config import cfg\n",
    "from lib.solver import Solver\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Hyperparameter\n",
    "BASE_LR = cfg.TRAIN.DEFAULT_LEARNING_RATE\n",
    "EPOCH_DECAY = 10 # number of epochs after which the Learning rate is decayed exponentially.\n",
    "DECAY_WEIGHT = cfg.TRAIN.WEIGHT_DECAY\n",
    "cfg.CONST.BATCH_SIZE = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def save_checkpoint(state, is_best, filename='checkpoint.pth.tar'):\n",
    "    torch.save(state, filename + '_latest.pth.tar')\n",
    "    if is_best:\n",
    "        shutil.copyfile(filename + '_latest.pth.tar', filename + '_best.pth.tar')\n",
    "\n",
    "\n",
    "def accuracy(output, target, topk=(1,)):\n",
    "    \"\"\"Computes the precision@k for the specified values of k\"\"\"\n",
    "    maxk = max(topk)\n",
    "    batch_size = target.size(0)\n",
    "\n",
    "    _, pred = output.topk(maxk, 1, True, True)\n",
    "    pred = pred.t()\n",
    "    correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
    "\n",
    "    res = []\n",
    "    for k in topk:\n",
    "        correct_k = correct[:k].view(-1).float().sum(0)\n",
    "        res.append(correct_k.mul_(100.0 / batch_size))\n",
    "    return res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1050816 43783\n"
     ]
    }
   ],
   "source": [
    "# training hyperparameters\n",
    "batch_size = cfg.CONST.BATCH_SIZE\n",
    "train_val_ratio = cfg.TRAIN.DATASET_PORTION[1]\n",
    "\n",
    "ren_len = dataset.ren_dataset.__len__()\n",
    "vox_len = dataset.vox_dataset.__len__()\n",
    "print(ren_len,vox_len)\n",
    "\n",
    "dict_ren1 = dataset.ren_dataset.class_to_idx\n",
    "list_ren = [[]]*(vox_len+1)\n",
    "\n",
    "for (path, idx) in dataset.ren_dataset.samples:\n",
    "    list_ren[idx] = list(set(list_ren[idx]))\n",
    "    list_ren[idx].append(path)\n",
    "\n",
    "\n",
    "dict_vox = {idx:path for (path, idx) in dataset.vox_dataset.samples}\n",
    "# print(list_ren[202][2])\n",
    "# print(dataset.center_crop(Image.open(list_ren[202][2])))\n",
    "# print(dict_vox[202])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# This function changes the learning rate over the training model.\n",
    "def exp_lr_scheduler(optimizer, epoch, init_lr=BASE_LR, lr_decay_epoch=EPOCH_DECAY):\n",
    "    \"\"\"Decay learning rate by a factor of DECAY_WEIGHT every lr_decay_epoch epochs.\"\"\"\n",
    "    lr = init_lr * (DECAY_WEIGHT**(epoch // lr_decay_epoch))\n",
    "\n",
    "    if epoch % lr_decay_epoch == 0:\n",
    "        print('LR is set to {}'.format(lr))\n",
    "\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = lr\n",
    "\n",
    "    return optimizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def testDataInput():\n",
    "    NetClass = load_model(cfg.CONST.NETWORK_CLASS)\n",
    "    # print('Network definition: \\n')\n",
    "    net = NetClass()\n",
    "    # print(net)\n",
    "\n",
    "    # start an epoch\n",
    "    # slice training and validation index\n",
    "    rand_idx = np.random.permutation(np.arange(vox_len))\n",
    "    thr = int(train_val_ratio*len(rand_idx))\n",
    "    train_idx = rand_idx[:thr]\n",
    "    val_idx = rand_idx[thr:]\n",
    "\n",
    "    batch_size = 4\n",
    "    max_num_views = 5\n",
    "\n",
    "    dict_vox = {idx:path for (path, idx) in dataset.vox_dataset.samples}\n",
    "\n",
    "\n",
    "    for i in range(thr//batch_size):\n",
    "\n",
    "        # for each batch\n",
    "        num_views = random.randint(2,max_num_views)\n",
    "\n",
    "        idx = train_idx[i*batch_size: (i+1)*batch_size]\n",
    "        voxel_loader = dataset.get_vox_data_loaders(idx)\n",
    "\n",
    "        label_list = []\n",
    "        for it, (labels, model_ids) in enumerate(voxel_loader):\n",
    "\n",
    "            batch_image = []\n",
    "            for model_id in model_ids:\n",
    "                image_list = []\n",
    "                image_ids = np.random.choice(cfg.TRAIN.NUM_RENDERING, num_views)\n",
    "    #             print(image_ids)\n",
    "                for n_view in range(num_views):\n",
    "                    image_list.append(dataset.center_crop(Image.open(list_ren[(model_id).item()][image_ids[n_view]]))[:3])\n",
    "\n",
    "                image_1 = torch.stack(image_list , dim=0)\n",
    "                batch_image.append(image_1)\n",
    "    #             print(image_1.shape)\n",
    "            batch_image = torch.stack(batch_image,dim=0)\n",
    "            batch_image = batch_image.transpose(1,0)\n",
    "    #         batch_image = batch_image.transpose(4,2)\n",
    "    #         batch_image = batch_image.transpose(4,3)\n",
    "\n",
    "            labels0 = (labels < 1)        \n",
    "            batch_voxel = torch.stack((labels0.float(),labels.float()),dim=0)\n",
    "            batch_voxel = batch_voxel.transpose(1,0)        \n",
    "\n",
    "            inputs=Variable(batch_image)\n",
    "            labels=Variable(batch_voxel)\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "        print(inputs.shape)\n",
    "        print(inputs[0].shape)\n",
    "        print(labels.shape)\n",
    "        # test mode\n",
    "        if i ==3:\n",
    "            break\n",
    "        # test mode end            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def run():\n",
    "    # Parameters\n",
    "    num_epochs = 10\n",
    "    output_period = 100\n",
    "    batch_size = cfg.CONST.BATCH_SIZE\n",
    "    \n",
    "    # setup the device for running\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(device)\n",
    "    \n",
    "    NetClass = load_model(cfg.CONST.NETWORK_CLASS)\n",
    "    model = NetClass().to(device)\n",
    "    \n",
    "    criterion = nn.CrossEntropyLoss().to(device)\n",
    "    \n",
    "    optimizer = optim.Adam(model.parameters(), lr=cfg.TRAIN.DEFAULT_LEARNING_RATE,weight_decay=cfg.TRAIN.WEIGHT_DECAY)\n",
    "    top1trset,top5trset = [],[]\n",
    "    top1set,top5set = [],[]\n",
    "    epoch = 1\n",
    "    while epoch <= num_epochs:\n",
    "        batch_time = AverageMeter()\n",
    "        data_time = AverageMeter()\n",
    "        losses = AverageMeter()\n",
    "        \n",
    "        running_loss = 0.0\n",
    "        optimizer = exp_lr_scheduler(optimizer, epoch)\n",
    "        for param_group in optimizer.param_groups:\n",
    "            print('Current learning rate: ' + str(param_group['lr']))\n",
    "            \n",
    "        model.train()\n",
    "\n",
    "        # start an epoch\n",
    "        # slice training and validation index\n",
    "        rand_idx = np.random.permutation(np.arange(vox_len))\n",
    "        thr = int(train_val_ratio*len(rand_idx))\n",
    "        train_idx = rand_idx[:thr]\n",
    "        val_idx = rand_idx[thr:]\n",
    "\n",
    "        max_num_views = 5\n",
    "\n",
    "        dict_vox = {idx:path for (path, idx) in dataset.vox_dataset.samples}\n",
    "\n",
    "        num_train_batches = thr//batch_size\n",
    "        for i in range(num_train_batches):\n",
    "\n",
    "            # for each batch\n",
    "            num_views = random.randint(2,max_num_views)\n",
    "\n",
    "            idx = train_idx[i*batch_size: (i+1)*batch_size]\n",
    "#             print(idx)\n",
    "            voxel_loader = dataset.get_vox_data_loaders(idx)\n",
    "\n",
    "            label_list = []\n",
    "            for it, (labels, model_ids) in enumerate(voxel_loader):\n",
    "\n",
    "                batch_image = []\n",
    "                for model_id in model_ids:\n",
    "                    image_list = []\n",
    "                    image_ids = np.random.choice(cfg.TRAIN.NUM_RENDERING, num_views)\n",
    "        #             print(image_ids)\n",
    "                    for n_view in range(num_views):\n",
    "                        image_list.append(dataset.center_crop(Image.open(list_ren[(model_id).item()][image_ids[n_view]]))[:3])\n",
    "\n",
    "                    image_1 = torch.stack(image_list , dim=0)\n",
    "                    batch_image.append(image_1)\n",
    "        #             print(image_1.shape)\n",
    "                batch_image = torch.stack(batch_image,dim=0)\n",
    "                batch_image = batch_image.transpose(1,0)\n",
    "\n",
    "                labels0 = (labels < 1)        \n",
    "                batch_voxel = torch.stack((labels0.float(),labels.float()),dim=0)\n",
    "                batch_voxel = batch_voxel.transpose(1,0)        \n",
    "\n",
    "                inputs=Variable(batch_image)\n",
    "                labels=Variable(labels)\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device).long()\n",
    "                \n",
    "                outputs = model(inputs,test=True)\n",
    "                \n",
    "#                 print('outputs[0].shape: ',outputs[0].shape)\n",
    "#                 print('labels.shape: ',labels.shape)\n",
    "                loss = criterion(outputs[0], labels)\n",
    "            \n",
    "    \n",
    "                # measure accuracy and record loss\n",
    "#                 prec1 = accuracy(outputs[0].data, labels, topk=(1,))\n",
    "                losses.update(loss.data.item(), inputs.size(0))\n",
    "#                 top1.update(prec1.item(), inputs.size(0))\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "            \n",
    "                running_loss += loss.item()\n",
    "        \n",
    "                if i % output_period == 0:\n",
    "                    print('[%d:%.2f] loss: %.3f' % (\n",
    "                        epoch, i*1.0/num_train_batches,\n",
    "                        running_loss/output_period\n",
    "                        ))\n",
    "                    running_loss = 0.0\n",
    "\n",
    "                    gc.collect()\n",
    "                \n",
    "            \n",
    "\n",
    "        gc.collect()\n",
    "        # save after every epoch\n",
    "        torch.save(model.state_dict(), \"models/model.%d\" % epoch)\n",
    "        \n",
    "        \n",
    "        model.eval()\n",
    "        \n",
    "        batch_size_val = batch_size\n",
    "        for i in range((len(rand_idx)-thr)//batch_size_val):\n",
    "            # for each batch\n",
    "            num_views = 1\n",
    "\n",
    "            idx = val_idx[i*batch_size_val: (i+1)*batch_size_val]\n",
    "            voxel_loader = dataset.get_vox_data_loaders(idx)\n",
    "\n",
    "            label_list = []\n",
    "            for it, (labels, model_ids) in enumerate(voxel_loader):\n",
    "\n",
    "                batch_image = []\n",
    "                for model_id in model_ids:\n",
    "                    image_list = []\n",
    "                    image_ids = np.random.choice(cfg.TRAIN.NUM_RENDERING, num_views)\n",
    "                    for n_view in range(num_views):\n",
    "                        image_list.append(dataset.center_crop(Image.open(list_ren[(model_id).item()][image_ids[n_view]]))[:3])\n",
    "\n",
    "                    image_1 = torch.stack(image_list , dim=0)\n",
    "                    batch_image.append(image_1)\n",
    "\n",
    "                batch_image = torch.stack(batch_image,dim=0)\n",
    "                batch_image = batch_image.transpose(1,0)\n",
    "\n",
    "                labels0 = (labels < 1)        \n",
    "                batch_voxel = torch.stack((labels0.float(),labels.float()),dim=0)\n",
    "                batch_voxel = batch_voxel.transpose(1,0)        \n",
    "\n",
    "                inputs=Variable(batch_image)\n",
    "                labels=Variable(labels)\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device).long()\n",
    "\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs[0], labels)\n",
    "    \n",
    "                # measure accuracy and record loss\n",
    "#                 prec1 = accuracy(outputs[0].data, labels, topk=(1,))\n",
    "                losses.update(loss.data.item(), inputs.size(0))\n",
    "#                 top1.update(prec1.item(), inputs.size(0))\n",
    "            \n",
    "        \n",
    "\n",
    "        print('test loss = '+ losses.avg)\n",
    "        \n",
    "        gc.collect()\n",
    "        epoch += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training\n",
      "cuda:0\n",
      "\n",
      "Your Model is \"ResidualGRUNet\" Initializing\n",
      "\n",
      "Initializing \"Encoder\"\n",
      "\n",
      "Initializing \"Decoder\"\n",
      "Current learning rate: 0.0001\n",
      "[1:0.00] loss: 0.007\n",
      "[1:0.05] loss: 0.420\n",
      "[1:0.09] loss: 0.393\n",
      "[1:0.14] loss: 0.394\n",
      "[1:0.18] loss: 0.387\n",
      "[1:0.23] loss: 0.388\n",
      "[1:0.27] loss: 0.391\n",
      "[1:0.32] loss: 0.390\n",
      "[1:0.37] loss: 0.390\n",
      "[1:0.41] loss: 0.392\n",
      "[1:0.46] loss: 0.388\n",
      "[1:0.50] loss: 0.387\n",
      "[1:0.55] loss: 0.387\n",
      "[1:0.59] loss: 0.387\n",
      "[1:0.64] loss: 0.390\n",
      "[1:0.69] loss: 0.385\n",
      "[1:0.73] loss: 0.385\n",
      "[1:0.78] loss: 0.388\n",
      "[1:0.82] loss: 0.388\n",
      "[1:0.87] loss: 0.383\n",
      "[1:0.91] loss: 0.385\n",
      "[1:0.96] loss: 0.384\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "must be str, not float",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-52f6aa77b51b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mBASE_LR\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDEFAULT_LEARNING_RATE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Training terminated'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-10-5d11ff3bb54d>\u001b[0m in \u001b[0;36mrun\u001b[0;34m()\u001b[0m\n\u001b[1;32m    156\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 158\u001b[0;31m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'test loss = '\u001b[0m\u001b[0;34m+\u001b[0m \u001b[0mlosses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mavg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    159\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m         \u001b[0mgc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: must be str, not float"
     ]
    }
   ],
   "source": [
    "print('Starting training')\n",
    "\n",
    "BASE_LR = cfg.TRAIN.DEFAULT_LEARNING_RATE\n",
    "run()\n",
    "print('Training terminated')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:torch36]",
   "language": "python",
   "name": "conda-env-torch36-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
